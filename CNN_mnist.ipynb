{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47749a1",
   "metadata": {},
   "source": [
    "# Deep Learning - MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f149d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "MODEL TRAINING:\n",
      "Epoch 1/5\n",
      "   5/1875 [..............................] - ETA: 32s - loss: 2.1990 - accuracy: 0.2625 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 23:43:10.171900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.4350 - accuracy: 0.8403\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2894 - accuracy: 0.8941\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2431 - accuracy: 0.9101\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2126 - accuracy: 0.9207\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1862 - accuracy: 0.9309\n",
      "\n",
      "MODEL EVALUATION:\n",
      " 25/313 [=>............................] - ETA: 1s - loss: 0.2801 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 23:44:19.249782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2648 - accuracy: 0.9050\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from tensorflow.keras import models\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    '''\n",
    "    Halts the training after reaching 60 percent accuracy\n",
    "\n",
    "    Args:\n",
    "      epoch (integer) - index of epoch (required but unused in the function definition below)\n",
    "      logs (dict) - metric results from the training epoch\n",
    "    '''\n",
    "\n",
    "    # Check accuracy\n",
    "    if(logs.get('loss') < 0.4):\n",
    "\n",
    "      # Stop if threshold is met\n",
    "      print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #parser = argparse.ArgumentParser(description=\"Build 5 layers convolutional neural network\" +\n",
    "     #                                \"predict MNIST data\")\n",
    "    #parser.add_argument('--vis', type=int, help='Plot figures 1 or 0',\n",
    "     #                   default=0)\n",
    "    #args = parser.parse_args()\n",
    "\n",
    "        \n",
    "    ####################### Load Data and get it ready ###################\n",
    " \n",
    "    # Load the Fashion MNIST dataset\n",
    "    \n",
    "    fmnist = tf.keras.datasets.fashion_mnist\n",
    "    (training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "    # Normalize the pixel values\n",
    "    training_images = training_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    training_images = training_images.reshape(-1, 28, 28, 1)\n",
    "    test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "    \n",
    "    #print(np.shape(training_images[0]))\n",
    "    #plt.imshow(training_images[0])\n",
    "    \n",
    "    \n",
    "    #============================ Build the Model=================================\n",
    "    \n",
    "    # Instantiate class\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    \n",
    "    # build the layers \n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Add convolutions and max pooling\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),     #64 layers of convolutions  \n",
    "        tf.keras.layers.MaxPooling2D(2, 2),                                       #maxpooling like compress picture  \n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # Add the same layers as before\n",
    "        tf.keras.layers.Flatten(),                                   \n",
    "        tf.keras.layers.Dense(128, activation='relu'),   \n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Print the model summar\n",
    "    model.summary()\n",
    "    # Compile \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    #=========================== Train the Model ==================================\n",
    "\n",
    "    print(f'\\nMODEL TRAINING:')    \n",
    "    model.fit(training_images, training_labels, epochs=5)\n",
    "    #model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
    "\n",
    "    #=========================== Evaluate the Model ================================\n",
    "    \n",
    "    print(f'\\nMODEL EVALUATION:')\n",
    "    test_loss = model.evaluate(test_images, test_labels)\n",
    "    \n",
    "    \n",
    "    #=========================== Predict and visualize =============================\n",
    "    #if args.vis ==1:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdcaa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "    f, axarr = plt.subplots(3,4)\n",
    "        \n",
    "        # pick three images\n",
    "    FIRST_IMAGE=0\n",
    "    SECOND_IMAGE=23\n",
    "    THIRD_IMAGE=28\n",
    "    CONVOLUTION_NUMBER = 60           # pick the convolution number to see the output at this conv     \n",
    "        \n",
    "    layer_outputs = [layer.output for layer in model.layers]        \n",
    "    activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)     \n",
    "    \n",
    "    for x in range(0,4):\n",
    "        f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "        axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "        axarr[0,x].grid(False)\n",
    "            \n",
    "        f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "        axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "        axarr[1,x].grid(False)\n",
    "            \n",
    "        f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "        axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "        axarr[2,x].grid(False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2a28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa20949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a5820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
